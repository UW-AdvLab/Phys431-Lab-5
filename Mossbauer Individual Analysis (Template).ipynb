{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Analysis for the M&ouml;ssbauer experiment\n",
    "\n",
    "Use this template to carry out the analysis tasks for the experiment.  For reference, here are links to recommended Python resources: the [Whirlwind Tour of Python](https://jakevdp.github.io/WhirlwindTourOfPython/) and the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) both by Jake VanderPlas.\n",
    "\n",
    "We will be making use of both the [Uncertainties](https://pythonhosted.org/uncertainties/) and [LMFit](https://lmfit.github.io/lmfit-py/) packages in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # import the numpy library functions.\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import uncertainties as unc # Uncertainties package.  Good for simple error propagation\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks for this analysis\n",
    "\n",
    "For each spectrum:\n",
    "\n",
    "1. Use the peak-to-peak amplitude from the velocity transducer and to create a calibration function (a line).  You will need the function generator period and MCS dwell time.  The function should return a velocity in mm/s given a channel number.  Negative velocities should indicate negative energy shifts, and positive velocities should indicate positive energy shifts.\n",
    "\n",
    "2. Apply your calibration function to the spectrum data sets for all spectra and plot them.\n",
    "\n",
    "3. Use LMFit and follow the tutorial on fitting a complicated multi-peak function to a data set to fit the absorption peaks to Lorentzians plus a parabolic (2nd order polynomial) background. (Note: you may, if you wish, fit each peak at a time rather than fit the entire spectrum with one complicated curve.)\n",
    "\n",
    "4. From the fits, obtain the peak center (with uncertainty) and peak width for each peak in each spectrum.  Record these results in tables, one table for each sample.  \n",
    "\n",
    "You will use the peak positions in mm/s to complete the data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the calibration function(s)\n",
    "\n",
    "Think carefully about the motion of the source: where is it at the begining of the scan?  which direction is it moving? \n",
    "\n",
    "Think carefully about the dwell time and how long an MCS cycle takes.  (One cycle is a run through all channels.)  At which channel is the velocity zero?  Which channel would have the highest velocity forward and which would have the highest velocity in reverse.  Once you know this, you create a line that interpolates between these points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \"dictionary\" to hold the peak-to-peak velocity transducer readings, in mV\n",
    "# You supply values and write the function.\n",
    "\n",
    "Vpp = {'Fe':, 'Nitroprusside':, 'Fe2O3':}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work on the first datafile\n",
    "\n",
    "Read in the first data file and then apply the calibration to convert channel numbers to velocity.  Plot the result.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The calibration, if done correctly, will flip the x-axis of the data set.  Assuming you are doing this on a column in a Pandas dataframe (the default when you read a csv file with `pd.read_csv()`) then the following will reorder the channel array so that the low index is on the left of the plot and the high index is on the right:\n",
    "\n",
    "`Fe_velocity = velocity_cal(Fe['Channel'],Vpp['Fe']).sort_values()`\n",
    "\n",
    "where `velocity_cal()` is the calibration function, `Fe['Channel']` is the data from the **Channel** column and `Vpp['Fe']` is the peak-to-peak voltage from the velocity transducer measurement.  The method attached to the end reorders the array from lowest to highest.\n",
    "\n",
    "***However I recommend the following.***  Just add another column to the dataframe which holds the converted channels-to-velocity.  This makes it easier to deal with slices of the array.  In other words do this:\n",
    "\n",
    "`Fe['velocity'] = velocity_cal(Fe['Channel'],Vpp['Fe'])`\n",
    "\n",
    "Then you can reference the original channels when you need to, but pass the velocity to the fitting routines when you need to get results in mm/s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data file, convert channels to velocity and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sanity plot\n",
    "myfig = plt.figure(figsize=(12,9))\n",
    "plt.grid()\n",
    "plt.xlabel(r'Velocity (mm/s)')\n",
    "plt.ylabel(r'Counts')\n",
    "plt.title('Mossbauer Data for Enriched Iron Sample')\n",
    "plt.plot(Fe['velocity'],Fe['Counts'],'.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plot against the column index to be able to esitmate a slice.  Take the slice and plot it to check. (these plots do not need to have axis labels, or be particularly big.)\n",
    "\n",
    "You will also want to plot against the velocity array in order to estimate the fitting parameter start values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(Fe['Counts'],'.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index = list(range(0,380))\n",
    "\n",
    "myfig = plt.figure(figsize=(12,9))\n",
    "plt.grid()\n",
    "plt.plot(Fe['velocity'][Index],Fe['Counts'][Index],'.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the slice to the model\n",
    "\n",
    "Now you should be reday to apply the procedure described in the **Composite Model Demo - Mossbauer** notebook.\n",
    "\n",
    "Below is a reminder of the basic steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the model\n",
    "\n",
    "The model fit will consist of two Lorentzian peaks and a quadratic background.\n",
    "\n",
    "The background fuction has the form\n",
    "$$f(x;a,b,c) = ax^2 + bx + c\\;.$$\n",
    "\n",
    "The Lorentzian lineshape has the form\n",
    "$$f(x;A,\\mu,\\sigma) = \\frac{A}{\\pi}\\left[\\frac{\\sigma}{(x-\\mu)^2 + \\sigma^2}\\right]\\;.$$ \n",
    "\n",
    "Note that the height of the peak at the center ($x=\\mu$) is equal to $\\frac{A}{\\pi\\sigma}$ and that the full-width at half-maximum is $2\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a gaussian peak and second order polynomial for background\n",
    "\n",
    "from lmfit.models import QuadraticModel, LorentzianModel\n",
    "\n",
    "# create an instance of the model\n",
    "# Note use of prefixes to keep parameters separate\n",
    "model1 = QuadraticModel() + LorentzianModel(prefix='p1_') + LorentzianModel(prefix='p2_')\n",
    "\n",
    "model = model1\n",
    "\n",
    "params = model.make_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the fit parameter starting points\n",
    "\n",
    "The first peak is shown as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['p1_center'].set(value=5.3, vary=True)\n",
    "params['p1_amplitude'].set(value=-4000.0*0.15*np.pi, vary=True)\n",
    "params['p1_sigma'].set(value=0.15, vary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fit.  The code below is an example.  Note the use of wieghts from Poisson statistics of counting and also the commands to resize the plot from the fitting routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(Fe['Counts'][Index], params, x=Fe['velocity'], weights=1/np.sqrt(Fe['Counts'][Index]))\n",
    "\n",
    "print(model_fit.fit_report(show_correl=False))\n",
    "\n",
    "myfig=plt.figure(figsize=(15,15))\n",
    "model_fit.plot(fig=myfig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have you succeeded with the above?\n",
    "\n",
    "If not,  try to fix it before mving on. If so, do the following:\n",
    "1. Save your current parameters\n",
    "2. Then\n",
    "   * Add another peak by expanding your slice or\n",
    "   * Choose a different slice and fit the peaks there\n",
    "3. Save your parameters and repeat.\n",
    "\n",
    "Your goal is to get good values of the peak locations.\n",
    "\n",
    "(When I did it, I added peaks, two at a time, until I got a fit for the whole scan.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the peak centers\n",
    "\n",
    "When you have obtained the best values, save the peak parameters.  I like to make a dataframe.  Here is one way to iterate over the parameters after they have been saved to extract the peak locations and uncertainties and make a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters from the best fit\n",
    "Fe_params = model_fit.params\n",
    "\n",
    "Fe_peaks = []\n",
    "for parm in Fe_params:\n",
    "    if parm.endswith('center'): \n",
    "        Fe_peaks.append(unc.ufloat(Fe_params[parm].value, Fe_params[parm].stderr))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fe_peaks_df = pd.DataFrame()\n",
    "Fe_peaks_df['Number'] = [1,2,3,4,5,6]\n",
    "Fe_peaks_df['Location (mm/s)'] = Fe_peaks\n",
    "Fe_peaks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the above procedure for the other data files.\n",
    "\n",
    "Remember: your goal here is a list of the best-fit peak locations in mm/s units for each data run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add as many cells as you need."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
